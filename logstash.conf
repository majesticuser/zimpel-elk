input {
  file {
    path => "/Users/virginio/projects/zimpel-elk/logs/*.log-*"
    start_position => beginning
    sincedb_path => "/Users/virginio/projects/zimpel-elk/sincedb25"
    debug => true
  }
}

filter {
  if ([path] =~ "application.log-*" and [message] =~ "Started") {
    grok {
      patterns_dir => "./logstash_grok_patterns"
      match => { "message" => "%{RAILS}" }
    }
    date {
      # see http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html
      # 2014-11-22 23:59:10
      match => ["log_ts", "yyyy-MM-dd HH:mm"]
    }
  }
  else if ([path] =~ "mailer.log-*" and [message] =~ "Sent mail to") {
    grok {
      match => { "message" => "Sent mail to %{NOTSPACE:email} \(%{NUMBER:send_duration_ms}ms\)" }
    }
  }
  else if ([path] =~ "solr.log-*") {
    grok {
      match => [ 
        "message", "(?<log_ts>%{YEAR:log_ts_year}-%{MONTHNUM:log_ts_month}-%{MONTHDAY:log_ts_day} %{HOUR:log_ts_hour}:%{MINUTE:log_ts_minute})"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_contact_language_id:\(%{DATA:job_search_contact_language_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_job_primary_subject_ids:\(%{DATA:job_search_job_primary_subject_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_job_subject_ids:\(%{DATA:job_search_job_subject_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_id:\(%{DATA:job_search_medium_id}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_geopath_ids:\(%{DATA:job_search_medium_geopath_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_frequency_id:\(%{DATA:job_search_medium_frequency_id}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_reach_id:\(%{DATA:job_search_medium_reach_id}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_city_ids:\(%{DATA:job_search_medium_city_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_node_1_ids:\(%{DATA:job_search_medium_node_1_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_country_ids:\(%{DATA:job_search_medium_country_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_adrate_range_id:\(%{DATA:job_search_medium_adrate_range_id}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_subject_ids:\(%{DATA:job_search_medium_subject_ids}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_medium_mediumtype_id:\(%{DATA:job_search_medium_mediumtype_id}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_location+pt\%3D%{DATA:job_search_location}%3D"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_fulltext_de:\(%{DATA:job_search_fulltext_de}\)"
      ]
    }
    grok {
      match => [ 
        "message", "job_search_fulltext_en:\(%{DATA:job_search_fulltext_en}\)"
      ]
    }

    date {
      # see http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html
      # 2014-11-22 23:59:10
      match => ["log_ts", "yyyy-MM-dd HH:mm"]
    }
  }
  else {
    drop{}
  }
}

output {
  stdout {
    codec => rubydebug
  }
  elasticsearch {
    # Setting 'embedded' will run  a real elasticsearch server inside logstash.
    # This option below saves you from having to run a separate process just
    # for ElasticSearch, so you can get started quicker!
    # embedded => true
    protocol => http
    index => 'logstash_zimpel'
  }
}
